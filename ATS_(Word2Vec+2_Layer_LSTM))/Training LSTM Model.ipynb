{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "#Drop columns which contains missing values\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the RNN.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 5-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "C:\\Users\\priya\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\priya\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10380/10380 [==============================] - 7s 632us/step - loss: 64.6328 - mean_absolute_error: 4.3330\n",
      "Epoch 2/50\n",
      "10380/10380 [==============================] - 5s 469us/step - loss: 38.8002 - mean_absolute_error: 3.4635\n",
      "Epoch 3/50\n",
      "10380/10380 [==============================] - 5s 472us/step - loss: 32.3473 - mean_absolute_error: 3.3775\n",
      "Epoch 4/50\n",
      "10380/10380 [==============================] - 5s 472us/step - loss: 29.6684 - mean_absolute_error: 3.3304\n",
      "Epoch 5/50\n",
      "10380/10380 [==============================] - 5s 520us/step - loss: 28.4386 - mean_absolute_error: 3.2837\n",
      "Epoch 6/50\n",
      "10380/10380 [==============================] - 6s 575us/step - loss: 27.0069 - mean_absolute_error: 3.1972\n",
      "Epoch 7/50\n",
      "10380/10380 [==============================] - 5s 516us/step - loss: 25.6421 - mean_absolute_error: 3.0560\n",
      "Epoch 8/50\n",
      "10380/10380 [==============================] - 5s 455us/step - loss: 24.8310 - mean_absolute_error: 2.9160\n",
      "Epoch 9/50\n",
      "10380/10380 [==============================] - 5s 465us/step - loss: 22.5929 - mean_absolute_error: 2.7449\n",
      "Epoch 10/50\n",
      "10380/10380 [==============================] - 5s 462us/step - loss: 20.0533 - mean_absolute_error: 2.6040\n",
      "Epoch 11/50\n",
      "10380/10380 [==============================] - 5s 456us/step - loss: 18.2889 - mean_absolute_error: 2.4721\n",
      "Epoch 12/50\n",
      "10380/10380 [==============================] - 5s 468us/step - loss: 17.0715 - mean_absolute_error: 2.3703\n",
      "Epoch 13/50\n",
      "10380/10380 [==============================] - 5s 467us/step - loss: 15.8714 - mean_absolute_error: 2.2709\n",
      "Epoch 14/50\n",
      "10380/10380 [==============================] - 5s 456us/step - loss: 14.7095 - mean_absolute_error: 2.2149\n",
      "Epoch 15/50\n",
      "10380/10380 [==============================] - 5s 464us/step - loss: 14.0061 - mean_absolute_error: 2.1546\n",
      "Epoch 16/50\n",
      "10380/10380 [==============================] - 5s 467us/step - loss: 13.6374 - mean_absolute_error: 2.1217\n",
      "Epoch 17/50\n",
      "10380/10380 [==============================] - 5s 460us/step - loss: 12.9190 - mean_absolute_error: 2.0350\n",
      "Epoch 18/50\n",
      "10380/10380 [==============================] - 5s 470us/step - loss: 12.9702 - mean_absolute_error: 2.0489\n",
      "Epoch 19/50\n",
      "10380/10380 [==============================] - 5s 470us/step - loss: 11.9598 - mean_absolute_error: 1.9594\n",
      "Epoch 20/50\n",
      "10380/10380 [==============================] - 5s 468us/step - loss: 11.9967 - mean_absolute_error: 1.9718\n",
      "Epoch 21/50\n",
      "10380/10380 [==============================] - 5s 458us/step - loss: 11.9204 - mean_absolute_error: 1.9293\n",
      "Epoch 22/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 10.6391 - mean_absolute_error: 1.8647\n",
      "Epoch 23/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 11.1413 - mean_absolute_error: 1.8873\n",
      "Epoch 24/50\n",
      "10380/10380 [==============================] - 5s 461us/step - loss: 10.4825 - mean_absolute_error: 1.8288\n",
      "Epoch 25/50\n",
      "10380/10380 [==============================] - 5s 470us/step - loss: 10.5863 - mean_absolute_error: 1.8222\n",
      "Epoch 26/50\n",
      "10380/10380 [==============================] - 5s 473us/step - loss: 9.8658 - mean_absolute_error: 1.7708\n",
      "Epoch 27/50\n",
      "10380/10380 [==============================] - 5s 466us/step - loss: 10.1256 - mean_absolute_error: 1.7765\n",
      "Epoch 28/50\n",
      "10380/10380 [==============================] - 5s 468us/step - loss: 9.5450 - mean_absolute_error: 1.7279\n",
      "Epoch 29/50\n",
      "10380/10380 [==============================] - 5s 479us/step - loss: 9.7885 - mean_absolute_error: 1.7556\n",
      "Epoch 30/50\n",
      "10380/10380 [==============================] - 5s 468us/step - loss: 9.5491 - mean_absolute_error: 1.7185\n",
      "Epoch 31/50\n",
      "10380/10380 [==============================] - 5s 463us/step - loss: 9.4711 - mean_absolute_error: 1.7229\n",
      "Epoch 32/50\n",
      "10380/10380 [==============================] - 5s 478us/step - loss: 9.2878 - mean_absolute_error: 1.7130\n",
      "Epoch 33/50\n",
      "10380/10380 [==============================] - 5s 472us/step - loss: 9.1724 - mean_absolute_error: 1.6783\n",
      "Epoch 34/50\n",
      "10380/10380 [==============================] - 5s 465us/step - loss: 8.9551 - mean_absolute_error: 1.6713\n",
      "Epoch 35/50\n",
      "10380/10380 [==============================] - 5s 479us/step - loss: 8.9030 - mean_absolute_error: 1.6728\n",
      "Epoch 36/50\n",
      "10380/10380 [==============================] - 5s 514us/step - loss: 8.8961 - mean_absolute_error: 1.6646\n",
      "Epoch 37/50\n",
      "10380/10380 [==============================] - 5s 490us/step - loss: 9.0112 - mean_absolute_error: 1.6608\n",
      "Epoch 38/50\n",
      "10380/10380 [==============================] - 5s 479us/step - loss: 8.5559 - mean_absolute_error: 1.6322\n",
      "Epoch 39/50\n",
      "10380/10380 [==============================] - 5s 482us/step - loss: 8.8313 - mean_absolute_error: 1.6533\n",
      "Epoch 40/50\n",
      "10380/10380 [==============================] - 5s 467us/step - loss: 8.4113 - mean_absolute_error: 1.6268\n",
      "Epoch 41/50\n",
      "10380/10380 [==============================] - 5s 474us/step - loss: 8.5329 - mean_absolute_error: 1.6206\n",
      "Epoch 42/50\n",
      "10380/10380 [==============================] - 5s 491us/step - loss: 8.1285 - mean_absolute_error: 1.6016 2s\n",
      "Epoch 43/50\n",
      "10380/10380 [==============================] - 5s 474us/step - loss: 8.0713 - mean_absolute_error: 1.5941\n",
      "Epoch 44/50\n",
      "10380/10380 [==============================] - 5s 475us/step - loss: 7.9496 - mean_absolute_error: 1.5882\n",
      "Epoch 45/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 8.1640 - mean_absolute_error: 1.5915\n",
      "Epoch 46/50\n",
      "10380/10380 [==============================] - 5s 480us/step - loss: 8.1946 - mean_absolute_error: 1.5899\n",
      "Epoch 47/50\n",
      "10380/10380 [==============================] - 5s 473us/step - loss: 8.0744 - mean_absolute_error: 1.5806\n",
      "Epoch 48/50\n",
      "10380/10380 [==============================] - 5s 484us/step - loss: 8.2515 - mean_absolute_error: 1.5882 0s - loss: 8.3009 - mean_absolute_error: 1.\n",
      "Epoch 49/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 8.1569 - mean_absolute_error: 1.5731\n",
      "Epoch 50/50\n",
      "10380/10380 [==============================] - 5s 473us/step - loss: 7.9712 - mean_absolute_error: 1.5573\n",
      "Kappa Score: 0.9587890009747664\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 7s 630us/step - loss: 60.9113 - mean_absolute_error: 4.2793\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 38.6770 - mean_absolute_error: 3.4489\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 32.0398 - mean_absolute_error: 3.3632\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 4s 433us/step - loss: 29.7822 - mean_absolute_error: 3.3241\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 27.8306 - mean_absolute_error: 3.2472\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 456us/step - loss: 26.9325 - mean_absolute_error: 3.1773\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 26.0796 - mean_absolute_error: 3.0763\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 446us/step - loss: 23.8983 - mean_absolute_error: 2.8660\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 21.1832 - mean_absolute_error: 2.6821\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 18.6062 - mean_absolute_error: 2.5250\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 17.3217 - mean_absolute_error: 2.4242\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 16.8250 - mean_absolute_error: 2.3339\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 457us/step - loss: 15.2486 - mean_absolute_error: 2.2530\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 453us/step - loss: 15.0291 - mean_absolute_error: 2.2206\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 5s 452us/step - loss: 13.6621 - mean_absolute_error: 2.1188\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 13.4162 - mean_absolute_error: 2.1102\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 13.1016 - mean_absolute_error: 2.0856\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 13.1612 - mean_absolute_error: 2.0721\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 464us/step - loss: 11.9770 - mean_absolute_error: 1.9964\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 464us/step - loss: 11.8079 - mean_absolute_error: 1.9692\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 11.5853 - mean_absolute_error: 1.9440\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 11.1813 - mean_absolute_error: 1.9022\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 10.8136 - mean_absolute_error: 1.8737\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 11.3377 - mean_absolute_error: 1.88260s - loss: 11.\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 453us/step - loss: 10.6291 - mean_absolute_error: 1.8288\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 9.9189 - mean_absolute_error: 1.7862\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 464us/step - loss: 9.6898 - mean_absolute_error: 1.7593\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 452us/step - loss: 9.7542 - mean_absolute_error: 1.7518\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 10.1587 - mean_absolute_error: 1.7741\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 465us/step - loss: 9.6719 - mean_absolute_error: 1.7287\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 9.7457 - mean_absolute_error: 1.7344\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 9.4813 - mean_absolute_error: 1.7125\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 473us/step - loss: 9.7797 - mean_absolute_error: 1.7297\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 5s 464us/step - loss: 9.2514 - mean_absolute_error: 1.6930\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 9.0891 - mean_absolute_error: 1.6771\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 8.9662 - mean_absolute_error: 1.6653\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.7236 - mean_absolute_error: 1.6386\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 8.5458 - mean_absolute_error: 1.6297\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.6577 - mean_absolute_error: 1.6397\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 479us/step - loss: 8.3684 - mean_absolute_error: 1.6125\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 462us/step - loss: 8.7015 - mean_absolute_error: 1.6296 2s\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 8.7807 - mean_absolute_error: 1.6380\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 8.5667 - mean_absolute_error: 1.6107\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 465us/step - loss: 8.5368 - mean_absolute_error: 1.6252\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 8.2816 - mean_absolute_error: 1.5934\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.4158 - mean_absolute_error: 1.6310\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 471us/step - loss: 8.3397 - mean_absolute_error: 1.6023\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 8.0392 - mean_absolute_error: 1.5690\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.1943 - mean_absolute_error: 1.5885\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 8.2013 - mean_absolute_error: 1.5731\n",
      "Kappa Score: 0.9571891650262375\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 6s 622us/step - loss: 62.3091 - mean_absolute_error: 4.2469\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 37.8785 - mean_absolute_error: 3.4588\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 32.3677 - mean_absolute_error: 3.3691\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 29.6675 - mean_absolute_error: 3.3022\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 28.9022 - mean_absolute_error: 3.2864\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 27.6510 - mean_absolute_error: 3.2015\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 26.2193 - mean_absolute_error: 3.0701\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 24.1746 - mean_absolute_error: 2.8785\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 22.1205 - mean_absolute_error: 2.7278\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 479us/step - loss: 18.9029 - mean_absolute_error: 2.5193\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 17.6851 - mean_absolute_error: 2.4280\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 16.2712 - mean_absolute_error: 2.3150\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 489us/step - loss: 15.3479 - mean_absolute_error: 2.2702\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 14.3032 - mean_absolute_error: 2.1854\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 5s 463us/step - loss: 14.0182 - mean_absolute_error: 2.1456\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 13.9050 - mean_absolute_error: 2.1259\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 13.4932 - mean_absolute_error: 2.0798\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 12.9392 - mean_absolute_error: 2.0469\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 12.0800 - mean_absolute_error: 2.0033\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 12.4328 - mean_absolute_error: 2.0009\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 11.7693 - mean_absolute_error: 1.9459\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 11.9669 - mean_absolute_error: 1.9571\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 11.6016 - mean_absolute_error: 1.9036\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 10.8174 - mean_absolute_error: 1.8784\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 462us/step - loss: 10.6363 - mean_absolute_error: 1.8286\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 464us/step - loss: 10.4103 - mean_absolute_error: 1.8130\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 10.5043 - mean_absolute_error: 1.8212\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 10.3257 - mean_absolute_error: 1.7720\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 10.4397 - mean_absolute_error: 1.7943\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 453us/step - loss: 10.3836 - mean_absolute_error: 1.7528\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 5s 457us/step - loss: 9.9061 - mean_absolute_error: 1.7561\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 5s 465us/step - loss: 9.8274 - mean_absolute_error: 1.7216\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 9.5929 - mean_absolute_error: 1.7172\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 5s 457us/step - loss: 9.5467 - mean_absolute_error: 1.7182\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 9.1434 - mean_absolute_error: 1.6838\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 471us/step - loss: 8.8888 - mean_absolute_error: 1.6640\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 9.0108 - mean_absolute_error: 1.6760\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 9.4982 - mean_absolute_error: 1.6758\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 473us/step - loss: 8.9202 - mean_absolute_error: 1.6506\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 8.9700 - mean_absolute_error: 1.6677 0s - loss: 8.9205 - mean_absolute_error: 1.66\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.6404 - mean_absolute_error: 1.6376 0s - loss: 8.7008 - mean_absolute_\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 471us/step - loss: 8.8613 - mean_absolute_error: 1.6414\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 8.9161 - mean_absolute_error: 1.6462\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 8.5180 - mean_absolute_error: 1.6099\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.7687 - mean_absolute_error: 1.6373\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 473us/step - loss: 8.7767 - mean_absolute_error: 1.6199\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 8.6134 - mean_absolute_error: 1.6224\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 8.4219 - mean_absolute_error: 1.6116\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 474us/step - loss: 8.2177 - mean_absolute_error: 1.5846 1s - loss: 8.5620 -\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 465us/step - loss: 8.2599 - mean_absolute_error: 1.5864\n",
      "Kappa Score: 0.9534837294784327\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 6s 625us/step - loss: 66.2019 - mean_absolute_error: 4.4221\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 437us/step - loss: 40.2585 - mean_absolute_error: 3.5599\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 493us/step - loss: 33.8182 - mean_absolute_error: 3.4689\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 30.5812 - mean_absolute_error: 3.4148\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 479us/step - loss: 29.6814 - mean_absolute_error: 3.3773: 2s\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 28.1599 - mean_absolute_error: 3.2937\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 4s 433us/step - loss: 26.8224 - mean_absolute_error: 3.1828\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 440us/step - loss: 26.4911 - mean_absolute_error: 3.0648\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 24.7416 - mean_absolute_error: 2.9115\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 22.6325 - mean_absolute_error: 2.7913\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 453us/step - loss: 20.1378 - mean_absolute_error: 2.6215\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - ETA: 0s - loss: 18.4091 - mean_absolute_error: 2.5108 ETA: 0s - loss: 18.4139 - 4s 432us/step - loss: 18.3889 - mean_absolute_error: 2.5090\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 16.1010 - mean_absolute_error: 2.3546\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 4s 403us/step - loss: 15.3303 - mean_absolute_error: 2.2569\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 4s 432us/step - loss: 14.5864 - mean_absolute_error: 2.1975\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 483us/step - loss: 13.9465 - mean_absolute_error: 2.1629\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 446us/step - loss: 13.0721 - mean_absolute_error: 2.0724\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 4s 432us/step - loss: 12.6576 - mean_absolute_error: 2.0486\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 12.3034 - mean_absolute_error: 2.0179\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 4s 425us/step - loss: 12.0093 - mean_absolute_error: 1.9814\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 4s 409us/step - loss: 11.6455 - mean_absolute_error: 1.9595\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 11.2627 - mean_absolute_error: 1.9125\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - ETA: 0s - loss: 10.6974 - mean_absolute_error: 1.85 - 5s 501us/step - loss: 10.7058 - mean_absolute_error: 1.8535\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 6s 549us/step - loss: 10.3891 - mean_absolute_error: 1.8567\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 10.4230 - mean_absolute_error: 1.8209\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 10.3026 - mean_absolute_error: 1.7984\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 9.9664 - mean_absolute_error: 1.7863\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 9.8645 - mean_absolute_error: 1.7696\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 483us/step - loss: 10.0196 - mean_absolute_error: 1.7700\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 474us/step - loss: 9.7904 - mean_absolute_error: 1.7366\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 5s 474us/step - loss: 9.6698 - mean_absolute_error: 1.7404\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 9.6963 - mean_absolute_error: 1.7308\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 9.5438 - mean_absolute_error: 1.7156\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 9.5664 - mean_absolute_error: 1.7017 2s -\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 9.0875 - mean_absolute_error: 1.6845\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 459us/step - loss: 9.0271 - mean_absolute_error: 1.6730\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 9.0082 - mean_absolute_error: 1.6653\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 8.9307 - mean_absolute_error: 1.6448\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 8.5507 - mean_absolute_error: 1.6437\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 8.6702 - mean_absolute_error: 1.6328\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 436us/step - loss: 8.8113 - mean_absolute_error: 1.6340\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 456us/step - loss: 9.0804 - mean_absolute_error: 1.6566\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 8.4426 - mean_absolute_error: 1.6087\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 435us/step - loss: 7.9578 - mean_absolute_error: 1.5751\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 8.3071 - mean_absolute_error: 1.6017 0s - loss: 8.2145 - mean_absolute_error: 1.59\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 457us/step - loss: 8.4091 - mean_absolute_error: 1.5935\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 441us/step - loss: 8.4670 - mean_absolute_error: 1.6049\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 439us/step - loss: 8.2888 - mean_absolute_error: 1.5871\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 452us/step - loss: 8.2499 - mean_absolute_error: 1.5888\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 8.2540 - mean_absolute_error: 1.5923\n",
      "Kappa Score: 0.9620835967774712\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 6s 612us/step - loss: 65.3064 - mean_absolute_error: 4.4075\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 4s 411us/step - loss: 39.1930 - mean_absolute_error: 3.4748\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 4s 398us/step - loss: 32.9518 - mean_absolute_error: 3.4021\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 4s 406us/step - loss: 30.3254 - mean_absolute_error: 3.3414\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 4s 421us/step - loss: 29.3180 - mean_absolute_error: 3.2927\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 4s 413us/step - loss: 28.4392 - mean_absolute_error: 3.2150\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 4s 404us/step - loss: 26.5957 - mean_absolute_error: 3.0599\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 4s 413us/step - loss: 24.0379 - mean_absolute_error: 2.8619\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 4s 422us/step - loss: 20.9485 - mean_absolute_error: 2.6959\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 4s 415us/step - loss: 18.6524 - mean_absolute_error: 2.5327\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 4s 408us/step - loss: 17.1942 - mean_absolute_error: 2.4103\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 4s 417us/step - loss: 16.2465 - mean_absolute_error: 2.3283\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 4s 426us/step - loss: 15.3545 - mean_absolute_error: 2.2822\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 14.9378 - mean_absolute_error: 2.2212\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 4s 418us/step - loss: 13.6126 - mean_absolute_error: 2.1393\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 4s 431us/step - loss: 13.9825 - mean_absolute_error: 2.1245\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 13.3593 - mean_absolute_error: 2.0848\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 4s 411us/step - loss: 13.2572 - mean_absolute_error: 2.0708\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 4s 413us/step - loss: 12.3036 - mean_absolute_error: 1.9981\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 4s 425us/step - loss: 11.7794 - mean_absolute_error: 1.9610\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 4s 418us/step - loss: 11.4892 - mean_absolute_error: 1.93521s - loss:\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 4s 410us/step - loss: 11.0267 - mean_absolute_error: 1.9015\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 4s 420us/step - loss: 11.3588 - mean_absolute_error: 1.9091\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 4s 425us/step - loss: 11.1109 - mean_absolute_error: 1.8838\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 4s 413us/step - loss: 11.0514 - mean_absolute_error: 1.8583\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 4s 411us/step - loss: 10.4723 - mean_absolute_error: 1.8240\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 4s 422us/step - loss: 10.4090 - mean_absolute_error: 1.8079\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 4s 422us/step - loss: 10.4884 - mean_absolute_error: 1.7973\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 4s 410us/step - loss: 10.0990 - mean_absolute_error: 1.7782\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 4s 418us/step - loss: 9.9893 - mean_absolute_error: 1.7588\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 4s 427us/step - loss: 10.1379 - mean_absolute_error: 1.75960s - loss: 10.2150 - mean_absolute_error: 1.\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 9.6523 - mean_absolute_error: 1.7373\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 9.5366 - mean_absolute_error: 1.7156\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 4s 421us/step - loss: 10.1873 - mean_absolute_error: 1.7604\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 4s 429us/step - loss: 9.5683 - mean_absolute_error: 1.7132\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 4s 410us/step - loss: 9.6061 - mean_absolute_error: 1.7118\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 4s 411us/step - loss: 9.6353 - mean_absolute_error: 1.6981\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 9.2614 - mean_absolute_error: 1.6962\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 9.3836 - mean_absolute_error: 1.6934\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 505us/step - loss: 9.1924 - mean_absolute_error: 1.6772 3s - loss: 9.108 - ETA: 1s - loss: 9.2016 - mean_absolute_err - ETA: 1s - loss: 9.4004 - mean_ab - ETA: 0s - loss: 9.2588 - mean_absolute_error: 1.68\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 499us/step - loss: 9.0345 - mean_absolute_error: 1.6526 3s - loss: 8.5749 - mean_absolute_error: 1\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 6s 538us/step - loss: 9.5031 - mean_absolute_error: 1.6796\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 527us/step - loss: 9.2008 - mean_absolute_error: 1.6624 1s - loss: 9.2516 - mean_absol\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 500us/step - loss: 8.5757 - mean_absolute_error: 1.6159 0s - loss: 8.5841 - mean_absolute_error:\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 8.7863 - mean_absolute_error: 1.6446\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 8.6556 - mean_absolute_error: 1.6215\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 479us/step - loss: 8.9489 - mean_absolute_error: 1.6324\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 505us/step - loss: 8.6154 - mean_absolute_error: 1.6133\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 8.6693 - mean_absolute_error: 1.6282\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 456us/step - loss: 8.7187 - mean_absolute_error: 1.5954\n",
      "Kappa Score: 0.9618077776855455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "# print(cv)\n",
    "\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(X):\n",
    "#     print(\"traincv=\", traincv)\n",
    "#     print(\"testcv=\", testcv)\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "#     print(\"X_train=\",X_train)\n",
    "#     print(\"y_train\",y_train)\n",
    "#     print(\"X_test\",X_test)\n",
    "#     print(\"y_test\",y_test)\n",
    "    train_essays = X_train['essay']\n",
    "#     print(\"train_essays=\",train_essays)\n",
    "    test_essays = X_test['essay']\n",
    "    sentences = []\n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Save models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avg. Kappa Score is 0.9587 which is the highest we have ever seen on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9587\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
